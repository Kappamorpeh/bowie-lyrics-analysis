{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ff30cba-8eb9-47ab-8345-608afd93bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re  \n",
    "import pandas as pd   \n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7653ce05-b5a9-4108-aea2-c5bead67f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f9bafd-5337-4508-8f83-d9a3c26f3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('bowie_data.json') as f:\n",
    "    bowie_data = json.load(f)\n",
    "bowie_data = pd.json_normalize(bowie_data, record_path=['Songs'], meta=['Name', 'Year'], meta_prefix='Album_', record_prefix='Song_')\n",
    "bowie_data = bowie_data[bowie_data['Song_Lyrics']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36b5e79-5d46-4100-adea-1a8cebe0ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_list_words = ['Version', \n",
    "                    'Mix', \n",
    "                    'Remix', \n",
    "                    'Mix)', \n",
    "                    '(Mix)', \n",
    "                    'Remix)', \n",
    "                    'Version)', \n",
    "                    'Edit)', \n",
    "                    '(Live)', \n",
    "                    '(Instrumental)', \n",
    "                    'Adler', \n",
    "                    'Reprise',\n",
    "                   ]\n",
    "# Create a regex pattern\n",
    "pattern = '|'.join(re.escape(word) for word in black_list_words)\n",
    "\n",
    "# Filter the DataFrame to remove rows where 'text_column' contains any of the words\n",
    "bowie_data = bowie_data[~bowie_data['Song_Name'].str.contains(pattern, case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d8d1286-5c6e-4542-8282-4f3f1f112ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics(lyrics):\n",
    "    # Remove contributor counts followed by song title and \"Lyrics\"\n",
    "    lyrics = re.sub(r'\\d+\\s+Contributors.*?Lyrics', '', lyrics)\n",
    "    \n",
    "    # Remove \"You Might Also Like\" sections\n",
    "    lyrics = re.sub(r'You might also like[^\\n]*', '', lyrics)\n",
    "    \n",
    "    # Remove \"Embed\" at the end\n",
    "    lyrics = re.sub(r'\\d*Embed$', '', lyrics)\n",
    "    \n",
    "    # Remove sections like [Verse 1], [Chorus], [Intro], [Outro], etc.\n",
    "    lyrics = re.sub(r'\\[.*?\\]', '', lyrics)\n",
    "    \n",
    "    # Remove all newline characters\n",
    "    lyrics = lyrics.replace('\\n', ' ')\n",
    "    \n",
    "    # Conver to lowercase\n",
    "    lyrics = lyrics.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    lyrics = re.sub(r'[^\\w\\s]', ' ', lyrics)\n",
    "    \n",
    "    # Remove zero-width spaces\n",
    "    lyrics = lyrics.replace('\\u200b', '')\n",
    "\n",
    "    # Collapse multiple spaces into a single space\n",
    "    lyrics = re.sub(r'\\s+', ' ', lyrics)\n",
    "    \n",
    "    # Strip leading and trailing whitespace\n",
    "    lyrics = lyrics.strip()\n",
    "    \n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eddf5c9f-ce6d-455a-968a-5c83db799ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowie_data['Song_Lyrics'] = bowie_data['Song_Lyrics'].apply(clean_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb1242c-c673-4b05-ba1a-744dad519dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['or', 'm', 'ma', 'ours', 'against', 'nor', \"it's\", 'o', \n",
    "                    'wasn', 'hasn', 'my', 'had', 'didn', 'isn', 'did', 'aren', 'those', 'than', \n",
    "                    \"mustn't\", \"you've\", 'to', 'she', 'having', \"haven't\", 'into', 't', 'll', \n",
    "                    'himself', 'do', \"that'll\", 'so', 'of', 'on', 'very', 'for', 'out', 'were', \n",
    "                    'should', 'they', 'ain', \"should've\", 'you', \"didn't\", 'yours', 'was', 'our',\n",
    "                     'can', 'myself', \"shouldn't\", 'have', 'up', 'mightn', \"you'll\", 'any', \n",
    "                    'itself', 'hadn', 'him', 'doesn', 'weren', 'y', 'being', \"don't\", 'them', \n",
    "                    'are','and', 'that', 'your', 'yourself', 'their', 'some', 'ourselves', 've', \n",
    "                    'doing', 'been', 'shouldn', 'yourselves', \"mightn't\", 'most', 'because',\n",
    "                     'few', 'wouldn', \"you'd\", 'through', \"you're\", 'themselves', 'an', 'if',\n",
    "                     \"wouldn't\", 'its', 'other', \"won't\", \"wasn't\", \"she's\", 'we', 'shan',\n",
    "                     \"weren't\",'don',\"hadn't\", 'this', 'off', 'while', 'a', 'haven', 'her', \n",
    "                    'theirs', 'all', \"hasn't\", \"doesn't\", 'about', 'then', 'by','such', 'but', \n",
    "                    'until', 'each', 'there', \"aren't\", 'with', 'not', \"shan't\", 'hers', 'it', \n",
    "                    'too', 'i', 'at', 'is', 'as', 'me', 'herself', 's', 'the', 'where', 'am', \n",
    "                    'has', 'over', \"couldn't\", 'when', 'does', 'mustn','re', 'no', 'in', 'who', \n",
    "                    'd', 'own', 'he', 'be', \"isn't\", 'his', 'these', 'same', 'whom', 'will', \n",
    "                    'needn','couldn', 'from', 'ah', 'yo', 'oh', 'yeah', 'ya', 'hey'\n",
    "                  ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64cfe164-78b1-4aac-830b-f3990560d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenise words & ignore punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    processed_words = [word for word in tokens if not word in stop_words]\n",
    "    processed_words = ' '.join(processed_words)\n",
    "    return processed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f8cf2bd-c2dd-4363-90b3-1903b0c27331",
   "metadata": {},
   "outputs": [],
   "source": [
    "bowie_data['Song_Lyrics'] = bowie_data['Song_Lyrics'].apply(preprocess_text)\n",
    "bowie_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b4175a-154d-44d9-909e-e8762a5b161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_years = []\n",
    "album_names = []\n",
    "song_names = []\n",
    "words = []\n",
    "\n",
    "for index, row in bowie_data.iterrows():\n",
    "    song_words = row['Song_Lyrics'].split()\n",
    "    \n",
    "    for word in song_words:\n",
    "        album_years.append(row['Album_Year'])\n",
    "        album_names.append(row['Album_Name'])\n",
    "        song_names.append(row['Song_Name'])\n",
    "        words.append(word)\n",
    "\n",
    "lyrics_by_words = pd.DataFrame({\n",
    "    'Album_Year': album_years,\n",
    "    'Album_Name': album_names,\n",
    "    'Song_Name': song_names,\n",
    "    'Word': words\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b085674-54c3-48c0-9206-56d12f7e46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bowie_cleaned_data.csv'\n",
    "bowie_data.to_csv(filename, index=False)\n",
    "\n",
    "filename = 'lyrics_by_words.csv'\n",
    "lyrics_by_words.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
